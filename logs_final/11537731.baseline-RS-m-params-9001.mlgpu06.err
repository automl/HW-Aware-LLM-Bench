cpu-bind=MASK - mlgpu06, task  0  0 [2177]: mask 0xc set
INFO:syne_tune.optimizer.schedulers.scheduler_searcher:Master random_seed = 9001
INFO:syne_tune.optimizer.schedulers.scheduler_searcher:max_resource_level = 1, as inferred from config_space
INFO:syne_tune.tuner:results of trials will be saved on /home/sukthank/syne-tune/mogpt-2024-05-30-12-11-23-336
INFO:syne_tune.backend.local_backend:Detected 0 GPUs
WARNING:syne_tune.backend.local_backend:num_gpus_per_trial = 1 is too large, reducing to 0
DEBUG:syne_tune.backend.local_backend:scheduling 0, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'params', 'device': 'v100', 'num_layers': 22, 'embed_dim': 256, 'bias': True, 'mlp_ratio_0': 2, 'num_heads_0': 8, 'mlp_ratio_1': 2, 'num_heads_1': 8, 'mlp_ratio_2': 2, 'num_heads_2': 8, 'mlp_ratio_3': 2, 'num_heads_3': 8, 'mlp_ratio_4': 2, 'num_heads_4': 8, 'mlp_ratio_5': 2, 'num_heads_5': 8, 'mlp_ratio_6': 2, 'num_heads_6': 8, 'mlp_ratio_7': 2, 'num_heads_7': 8, 'mlp_ratio_8': 2, 'num_heads_8': 8, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 2, 'num_heads_10': 8, 'mlp_ratio_11': 2, 'num_heads_11': 8, 'mlp_ratio_12': 2, 'num_heads_12': 8, 'mlp_ratio_13': 2, 'num_heads_13': 8, 'mlp_ratio_14': 2, 'num_heads_14': 8, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 2, 'num_heads_17': 8, 'mlp_ratio_18': 2, 'num_heads_18': 8, 'mlp_ratio_19': 2, 'num_heads_19': 8, 'mlp_ratio_20': 2, 'num_heads_20': 8, 'mlp_ratio_21': 2, 'num_heads_21': 8, 'mlp_ratio_22': 2, 'num_heads_22': 8, 'mlp_ratio_23': 2, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-11-23-336/0
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective params --device v100 --num_layers 22 --embed_dim 256 --bias True --mlp_ratio_0 2 --num_heads_0 8 --mlp_ratio_1 2 --num_heads_1 8 --mlp_ratio_2 2 --num_heads_2 8 --mlp_ratio_3 2 --num_heads_3 8 --mlp_ratio_4 2 --num_heads_4 8 --mlp_ratio_5 2 --num_heads_5 8 --mlp_ratio_6 2 --num_heads_6 8 --mlp_ratio_7 2 --num_heads_7 8 --mlp_ratio_8 2 --num_heads_8 8 --mlp_ratio_9 2 --num_heads_9 8 --mlp_ratio_10 2 --num_heads_10 8 --mlp_ratio_11 2 --num_heads_11 8 --mlp_ratio_12 2 --num_heads_12 8 --mlp_ratio_13 2 --num_heads_13 8 --mlp_ratio_14 2 --num_heads_14 8 --mlp_ratio_15 2 --num_heads_15 8 --mlp_ratio_16 2 --num_heads_16 8 --mlp_ratio_17 2 --num_heads_17 8 --mlp_ratio_18 2 --num_heads_18 8 --mlp_ratio_19 2 --num_heads_19 8 --mlp_ratio_20 2 --num_heads_20 8 --mlp_ratio_21 2 --num_heads_21 8 --mlp_ratio_22 2 --num_heads_22 8 --mlp_ratio_23 2 --num_heads_23 8 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-11-23-336/0/checkpoints
INFO:syne_tune.tuner:(trial 0) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'params', 'device': 'v100', 'num_layers': 22, 'embed_dim': 256, 'bias': True, 'mlp_ratio_0': 2, 'num_heads_0': 8, 'mlp_ratio_1': 2, 'num_heads_1': 8, 'mlp_ratio_2': 2, 'num_heads_2': 8, 'mlp_ratio_3': 2, 'num_heads_3': 8, 'mlp_ratio_4': 2, 'num_heads_4': 8, 'mlp_ratio_5': 2, 'num_heads_5': 8, 'mlp_ratio_6': 2, 'num_heads_6': 8, 'mlp_ratio_7': 2, 'num_heads_7': 8, 'mlp_ratio_8': 2, 'num_heads_8': 8, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 2, 'num_heads_10': 8, 'mlp_ratio_11': 2, 'num_heads_11': 8, 'mlp_ratio_12': 2, 'num_heads_12': 8, 'mlp_ratio_13': 2, 'num_heads_13': 8, 'mlp_ratio_14': 2, 'num_heads_14': 8, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 2, 'num_heads_17': 8, 'mlp_ratio_18': 2, 'num_heads_18': 8, 'mlp_ratio_19': 2, 'num_heads_19': 8, 'mlp_ratio_20': 2, 'num_heads_20': 8, 'mlp_ratio_21': 2, 'num_heads_21': 8, 'mlp_ratio_22': 2, 'num_heads_22': 8, 'mlp_ratio_23': 2, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
slurmstepd-mlgpu06: error: *** JOB 11537731 ON mlgpu06 CANCELLED AT 2024-05-30T14:11:46 ***
