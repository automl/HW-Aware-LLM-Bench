cpu-bind=MASK - mlgpu12, task  0  0 [2625]: mask 0x3 set
INFO:syne_tune.optimizer.schedulers.scheduler_searcher:Master random_seed = 9001
INFO:syne_tune.optimizer.schedulers.scheduler_searcher:max_resource_level = 1, as inferred from config_space
INFO:syne_tune.tuner:results of trials will be saved on /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726
INFO:syne_tune.backend.local_backend:Detected 1 GPUs
DEBUG:syne_tune.backend.local_backend:scheduling 0, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 24, 'embed_dim': 256, 'bias': False, 'mlp_ratio_0': 3, 'num_heads_0': 8, 'mlp_ratio_1': 3, 'num_heads_1': 12, 'mlp_ratio_2': 3, 'num_heads_2': 8, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 12, 'mlp_ratio_5': 3, 'num_heads_5': 16, 'mlp_ratio_6': 3, 'num_heads_6': 8, 'mlp_ratio_7': 2, 'num_heads_7': 8, 'mlp_ratio_8': 2, 'num_heads_8': 8, 'mlp_ratio_9': 4, 'num_heads_9': 16, 'mlp_ratio_10': 2, 'num_heads_10': 16, 'mlp_ratio_11': 2, 'num_heads_11': 16, 'mlp_ratio_12': 3, 'num_heads_12': 12, 'mlp_ratio_13': 4, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 12, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 12, 'mlp_ratio_17': 4, 'num_heads_17': 12, 'mlp_ratio_18': 3, 'num_heads_18': 12, 'mlp_ratio_19': 4, 'num_heads_19': 12, 'mlp_ratio_20': 3, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 12, 'mlp_ratio_22': 3, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/0
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 24 --embed_dim 256 --bias False --mlp_ratio_0 3 --num_heads_0 8 --mlp_ratio_1 3 --num_heads_1 12 --mlp_ratio_2 3 --num_heads_2 8 --mlp_ratio_3 4 --num_heads_3 8 --mlp_ratio_4 3 --num_heads_4 12 --mlp_ratio_5 3 --num_heads_5 16 --mlp_ratio_6 3 --num_heads_6 8 --mlp_ratio_7 2 --num_heads_7 8 --mlp_ratio_8 2 --num_heads_8 8 --mlp_ratio_9 4 --num_heads_9 16 --mlp_ratio_10 2 --num_heads_10 16 --mlp_ratio_11 2 --num_heads_11 16 --mlp_ratio_12 3 --num_heads_12 12 --mlp_ratio_13 4 --num_heads_13 8 --mlp_ratio_14 4 --num_heads_14 12 --mlp_ratio_15 2 --num_heads_15 8 --mlp_ratio_16 2 --num_heads_16 12 --mlp_ratio_17 4 --num_heads_17 12 --mlp_ratio_18 3 --num_heads_18 12 --mlp_ratio_19 4 --num_heads_19 12 --mlp_ratio_20 3 --num_heads_20 8 --mlp_ratio_21 4 --num_heads_21 12 --mlp_ratio_22 3 --num_heads_22 12 --mlp_ratio_23 4 --num_heads_23 12 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/0/checkpoints
INFO:syne_tune.tuner:(trial 0) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 24, 'embed_dim': 256, 'bias': False, 'mlp_ratio_0': 3, 'num_heads_0': 8, 'mlp_ratio_1': 3, 'num_heads_1': 12, 'mlp_ratio_2': 3, 'num_heads_2': 8, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 12, 'mlp_ratio_5': 3, 'num_heads_5': 16, 'mlp_ratio_6': 3, 'num_heads_6': 8, 'mlp_ratio_7': 2, 'num_heads_7': 8, 'mlp_ratio_8': 2, 'num_heads_8': 8, 'mlp_ratio_9': 4, 'num_heads_9': 16, 'mlp_ratio_10': 2, 'num_heads_10': 16, 'mlp_ratio_11': 2, 'num_heads_11': 16, 'mlp_ratio_12': 3, 'num_heads_12': 12, 'mlp_ratio_13': 4, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 12, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 12, 'mlp_ratio_17': 4, 'num_heads_17': 12, 'mlp_ratio_18': 3, 'num_heads_18': 12, 'mlp_ratio_19': 4, 'num_heads_19': 12, 'mlp_ratio_20': 3, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 12, 'mlp_ratio_22': 3, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.optimizer.schedulers.fifo:trial_id 0 (perplexity = 1.340, hw_metric = -1.056): decision = CONTINUE
DEBUG:syne_tune.tuner:saving tuner in /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/tuner.dill
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
INFO:syne_tune.tuner:Trial trial_id 0 completed.
DEBUG:syne_tune.backend.local_backend:scheduling 1, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 24, 'embed_dim': 512, 'bias': False, 'mlp_ratio_0': 4, 'num_heads_0': 8, 'mlp_ratio_1': 3, 'num_heads_1': 12, 'mlp_ratio_2': 2, 'num_heads_2': 12, 'mlp_ratio_3': 3, 'num_heads_3': 8, 'mlp_ratio_4': 4, 'num_heads_4': 12, 'mlp_ratio_5': 2, 'num_heads_5': 8, 'mlp_ratio_6': 3, 'num_heads_6': 16, 'mlp_ratio_7': 4, 'num_heads_7': 8, 'mlp_ratio_8': 3, 'num_heads_8': 8, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 16, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 8, 'mlp_ratio_13': 3, 'num_heads_13': 12, 'mlp_ratio_14': 2, 'num_heads_14': 12, 'mlp_ratio_15': 3, 'num_heads_15': 8, 'mlp_ratio_16': 3, 'num_heads_16': 16, 'mlp_ratio_17': 4, 'num_heads_17': 12, 'mlp_ratio_18': 4, 'num_heads_18': 8, 'mlp_ratio_19': 2, 'num_heads_19': 16, 'mlp_ratio_20': 2, 'num_heads_20': 12, 'mlp_ratio_21': 4, 'num_heads_21': 12, 'mlp_ratio_22': 4, 'num_heads_22': 16, 'mlp_ratio_23': 4, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/1
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 24 --embed_dim 512 --bias False --mlp_ratio_0 4 --num_heads_0 8 --mlp_ratio_1 3 --num_heads_1 12 --mlp_ratio_2 2 --num_heads_2 12 --mlp_ratio_3 3 --num_heads_3 8 --mlp_ratio_4 4 --num_heads_4 12 --mlp_ratio_5 2 --num_heads_5 8 --mlp_ratio_6 3 --num_heads_6 16 --mlp_ratio_7 4 --num_heads_7 8 --mlp_ratio_8 3 --num_heads_8 8 --mlp_ratio_9 2 --num_heads_9 8 --mlp_ratio_10 4 --num_heads_10 16 --mlp_ratio_11 4 --num_heads_11 12 --mlp_ratio_12 2 --num_heads_12 8 --mlp_ratio_13 3 --num_heads_13 12 --mlp_ratio_14 2 --num_heads_14 12 --mlp_ratio_15 3 --num_heads_15 8 --mlp_ratio_16 3 --num_heads_16 16 --mlp_ratio_17 4 --num_heads_17 12 --mlp_ratio_18 4 --num_heads_18 8 --mlp_ratio_19 2 --num_heads_19 16 --mlp_ratio_20 2 --num_heads_20 12 --mlp_ratio_21 4 --num_heads_21 12 --mlp_ratio_22 4 --num_heads_22 16 --mlp_ratio_23 4 --num_heads_23 8 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/1/checkpoints
INFO:syne_tune.tuner:(trial 1) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 24, 'embed_dim': 512, 'bias': False, 'mlp_ratio_0': 4, 'num_heads_0': 8, 'mlp_ratio_1': 3, 'num_heads_1': 12, 'mlp_ratio_2': 2, 'num_heads_2': 12, 'mlp_ratio_3': 3, 'num_heads_3': 8, 'mlp_ratio_4': 4, 'num_heads_4': 12, 'mlp_ratio_5': 2, 'num_heads_5': 8, 'mlp_ratio_6': 3, 'num_heads_6': 16, 'mlp_ratio_7': 4, 'num_heads_7': 8, 'mlp_ratio_8': 3, 'num_heads_8': 8, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 16, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 8, 'mlp_ratio_13': 3, 'num_heads_13': 12, 'mlp_ratio_14': 2, 'num_heads_14': 12, 'mlp_ratio_15': 3, 'num_heads_15': 8, 'mlp_ratio_16': 3, 'num_heads_16': 16, 'mlp_ratio_17': 4, 'num_heads_17': 12, 'mlp_ratio_18': 4, 'num_heads_18': 8, 'mlp_ratio_19': 2, 'num_heads_19': 16, 'mlp_ratio_20': 2, 'num_heads_20': 12, 'mlp_ratio_21': 4, 'num_heads_21': 12, 'mlp_ratio_22': 4, 'num_heads_22': 16, 'mlp_ratio_23': 4, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
INFO:syne_tune.tuner:tuning status (last metric is reported)
 trial_id     status  iter     type search_space surrogate_type objective device  num_layers  embed_dim  bias  mlp_ratio_0  num_heads_0  mlp_ratio_1  num_heads_1  mlp_ratio_2  num_heads_2  mlp_ratio_3  num_heads_3  mlp_ratio_4  num_heads_4  mlp_ratio_5  num_heads_5  mlp_ratio_6  num_heads_6  mlp_ratio_7  num_heads_7  mlp_ratio_8  num_heads_8  mlp_ratio_9  num_heads_9  mlp_ratio_10  num_heads_10  mlp_ratio_11  num_heads_11  mlp_ratio_12  num_heads_12  mlp_ratio_13  num_heads_13  mlp_ratio_14  num_heads_14  mlp_ratio_15  num_heads_15  mlp_ratio_16  num_heads_16  mlp_ratio_17  num_heads_17  mlp_ratio_18  num_heads_18  mlp_ratio_19  num_heads_19  mlp_ratio_20  num_heads_20  mlp_ratio_21  num_heads_21  mlp_ratio_22  num_heads_22  mlp_ratio_23  num_heads_23  epochs dataset_path  perplexity  hw_metric  worker-time
        0  Completed     1 quantile            m            mlp     flops   v100          24        256 False            3            8            3           12            3            8            4            8            3           12            3           16            3            8            2            8            2            8            4           16             2            16             2            16             3            12             4             8             4            12             2             8             2            12             4            12             3            12             4            12             3             8             4            12             3            12             4            12       1           ./    1.340196  -1.055749      0.72716
        1 InProgress     0 quantile            m            mlp     flops   v100          24        512 False            4            8            3           12            2           12            3            8            4           12            2            8            3           16            4            8            3            8            2            8             4            16             4            12             2             8             3            12             2            12             3             8             3            16             4            12             4             8             2            16             2            12             4            12             4            16             4             8       1           ./           -          -            -
1 trials running, 1 finished (1 until the end), 35.28s wallclock-time

DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.optimizer.schedulers.fifo:trial_id 1 (perplexity = -0.121, hw_metric = -0.472): decision = CONTINUE
INFO:syne_tune.tuner:Trial trial_id 1 completed.
DEBUG:syne_tune.tuner:saving tuner in /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/tuner.dill
DEBUG:syne_tune.backend.local_backend:scheduling 2, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 24, 'embed_dim': 256, 'bias': True, 'mlp_ratio_0': 3, 'num_heads_0': 12, 'mlp_ratio_1': 4, 'num_heads_1': 12, 'mlp_ratio_2': 3, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 2, 'num_heads_4': 16, 'mlp_ratio_5': 3, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 16, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 2, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 2, 'num_heads_10': 8, 'mlp_ratio_11': 4, 'num_heads_11': 8, 'mlp_ratio_12': 4, 'num_heads_12': 8, 'mlp_ratio_13': 3, 'num_heads_13': 16, 'mlp_ratio_14': 4, 'num_heads_14': 8, 'mlp_ratio_15': 4, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 16, 'mlp_ratio_17': 2, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 8, 'mlp_ratio_19': 2, 'num_heads_19': 16, 'mlp_ratio_20': 3, 'num_heads_20': 16, 'mlp_ratio_21': 2, 'num_heads_21': 16, 'mlp_ratio_22': 4, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/2
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 24 --embed_dim 256 --bias True --mlp_ratio_0 3 --num_heads_0 12 --mlp_ratio_1 4 --num_heads_1 12 --mlp_ratio_2 3 --num_heads_2 12 --mlp_ratio_3 4 --num_heads_3 8 --mlp_ratio_4 2 --num_heads_4 16 --mlp_ratio_5 3 --num_heads_5 12 --mlp_ratio_6 3 --num_heads_6 16 --mlp_ratio_7 4 --num_heads_7 12 --mlp_ratio_8 2 --num_heads_8 16 --mlp_ratio_9 2 --num_heads_9 8 --mlp_ratio_10 2 --num_heads_10 8 --mlp_ratio_11 4 --num_heads_11 8 --mlp_ratio_12 4 --num_heads_12 8 --mlp_ratio_13 3 --num_heads_13 16 --mlp_ratio_14 4 --num_heads_14 8 --mlp_ratio_15 4 --num_heads_15 8 --mlp_ratio_16 2 --num_heads_16 16 --mlp_ratio_17 2 --num_heads_17 8 --mlp_ratio_18 4 --num_heads_18 8 --mlp_ratio_19 2 --num_heads_19 16 --mlp_ratio_20 3 --num_heads_20 16 --mlp_ratio_21 2 --num_heads_21 16 --mlp_ratio_22 4 --num_heads_22 12 --mlp_ratio_23 4 --num_heads_23 8 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/2/checkpoints
INFO:syne_tune.tuner:(trial 2) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 24, 'embed_dim': 256, 'bias': True, 'mlp_ratio_0': 3, 'num_heads_0': 12, 'mlp_ratio_1': 4, 'num_heads_1': 12, 'mlp_ratio_2': 3, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 2, 'num_heads_4': 16, 'mlp_ratio_5': 3, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 16, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 2, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 2, 'num_heads_10': 8, 'mlp_ratio_11': 4, 'num_heads_11': 8, 'mlp_ratio_12': 4, 'num_heads_12': 8, 'mlp_ratio_13': 3, 'num_heads_13': 16, 'mlp_ratio_14': 4, 'num_heads_14': 8, 'mlp_ratio_15': 4, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 16, 'mlp_ratio_17': 2, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 8, 'mlp_ratio_19': 2, 'num_heads_19': 16, 'mlp_ratio_20': 3, 'num_heads_20': 16, 'mlp_ratio_21': 2, 'num_heads_21': 16, 'mlp_ratio_22': 4, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
INFO:syne_tune.tuner:tuning status (last metric is reported)
 trial_id     status  iter     type search_space surrogate_type objective device  num_layers  embed_dim  bias  mlp_ratio_0  num_heads_0  mlp_ratio_1  num_heads_1  mlp_ratio_2  num_heads_2  mlp_ratio_3  num_heads_3  mlp_ratio_4  num_heads_4  mlp_ratio_5  num_heads_5  mlp_ratio_6  num_heads_6  mlp_ratio_7  num_heads_7  mlp_ratio_8  num_heads_8  mlp_ratio_9  num_heads_9  mlp_ratio_10  num_heads_10  mlp_ratio_11  num_heads_11  mlp_ratio_12  num_heads_12  mlp_ratio_13  num_heads_13  mlp_ratio_14  num_heads_14  mlp_ratio_15  num_heads_15  mlp_ratio_16  num_heads_16  mlp_ratio_17  num_heads_17  mlp_ratio_18  num_heads_18  mlp_ratio_19  num_heads_19  mlp_ratio_20  num_heads_20  mlp_ratio_21  num_heads_21  mlp_ratio_22  num_heads_22  mlp_ratio_23  num_heads_23  epochs dataset_path  perplexity  hw_metric  worker-time
        0  Completed     1 quantile            m            mlp     flops   v100          24        256 False            3            8            3           12            3            8            4            8            3           12            3           16            3            8            2            8            2            8            4           16             2            16             2            16             3            12             4             8             4            12             2             8             2            12             4            12             3            12             4            12             3             8             4            12             3            12             4            12       1           ./    1.340196  -1.055749     0.727160
        1  Completed     1 quantile            m            mlp     flops   v100          24        512 False            4            8            3           12            2           12            3            8            4           12            2            8            3           16            4            8            3            8            2            8             4            16             4            12             2             8             3            12             2            12             3             8             3            16             4            12             4             8             2            16             2            12             4            12             4            16             4             8       1           ./   -0.120630  -0.471518     0.345232
        2 InProgress     0 quantile            m            mlp     flops   v100          24        256  True            3           12            4           12            3           12            4            8            2           16            3           12            3           16            4           12            2           16            2            8             2             8             4             8             4             8             3            16             4             8             4             8             2            16             2             8             4             8             2            16             3            16             2            16             4            12             4             8       1           ./           -          -            -
1 trials running, 2 finished (2 until the end), 70.42s wallclock-time

DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.optimizer.schedulers.fifo:trial_id 2 (perplexity = 1.413, hw_metric = -1.037): decision = CONTINUE
INFO:syne_tune.tuner:Trial trial_id 2 completed.
DEBUG:syne_tune.tuner:saving tuner in /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/tuner.dill
DEBUG:syne_tune.backend.local_backend:scheduling 3, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 1024, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 16, 'mlp_ratio_1': 4, 'num_heads_1': 16, 'mlp_ratio_2': 3, 'num_heads_2': 8, 'mlp_ratio_3': 2, 'num_heads_3': 12, 'mlp_ratio_4': 3, 'num_heads_4': 16, 'mlp_ratio_5': 3, 'num_heads_5': 8, 'mlp_ratio_6': 2, 'num_heads_6': 8, 'mlp_ratio_7': 4, 'num_heads_7': 8, 'mlp_ratio_8': 4, 'num_heads_8': 8, 'mlp_ratio_9': 4, 'num_heads_9': 12, 'mlp_ratio_10': 3, 'num_heads_10': 12, 'mlp_ratio_11': 2, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 8, 'mlp_ratio_13': 4, 'num_heads_13': 12, 'mlp_ratio_14': 3, 'num_heads_14': 16, 'mlp_ratio_15': 4, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 16, 'mlp_ratio_17': 2, 'num_heads_17': 16, 'mlp_ratio_18': 3, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 8, 'mlp_ratio_20': 2, 'num_heads_20': 8, 'mlp_ratio_21': 2, 'num_heads_21': 16, 'mlp_ratio_22': 3, 'num_heads_22': 8, 'mlp_ratio_23': 4, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/3
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 23 --embed_dim 1024 --bias True --mlp_ratio_0 4 --num_heads_0 16 --mlp_ratio_1 4 --num_heads_1 16 --mlp_ratio_2 3 --num_heads_2 8 --mlp_ratio_3 2 --num_heads_3 12 --mlp_ratio_4 3 --num_heads_4 16 --mlp_ratio_5 3 --num_heads_5 8 --mlp_ratio_6 2 --num_heads_6 8 --mlp_ratio_7 4 --num_heads_7 8 --mlp_ratio_8 4 --num_heads_8 8 --mlp_ratio_9 4 --num_heads_9 12 --mlp_ratio_10 3 --num_heads_10 12 --mlp_ratio_11 2 --num_heads_11 12 --mlp_ratio_12 2 --num_heads_12 8 --mlp_ratio_13 4 --num_heads_13 12 --mlp_ratio_14 3 --num_heads_14 16 --mlp_ratio_15 4 --num_heads_15 8 --mlp_ratio_16 2 --num_heads_16 16 --mlp_ratio_17 2 --num_heads_17 16 --mlp_ratio_18 3 --num_heads_18 16 --mlp_ratio_19 4 --num_heads_19 8 --mlp_ratio_20 2 --num_heads_20 8 --mlp_ratio_21 2 --num_heads_21 16 --mlp_ratio_22 3 --num_heads_22 8 --mlp_ratio_23 4 --num_heads_23 8 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/3/checkpoints
INFO:syne_tune.tuner:(trial 3) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 1024, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 16, 'mlp_ratio_1': 4, 'num_heads_1': 16, 'mlp_ratio_2': 3, 'num_heads_2': 8, 'mlp_ratio_3': 2, 'num_heads_3': 12, 'mlp_ratio_4': 3, 'num_heads_4': 16, 'mlp_ratio_5': 3, 'num_heads_5': 8, 'mlp_ratio_6': 2, 'num_heads_6': 8, 'mlp_ratio_7': 4, 'num_heads_7': 8, 'mlp_ratio_8': 4, 'num_heads_8': 8, 'mlp_ratio_9': 4, 'num_heads_9': 12, 'mlp_ratio_10': 3, 'num_heads_10': 12, 'mlp_ratio_11': 2, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 8, 'mlp_ratio_13': 4, 'num_heads_13': 12, 'mlp_ratio_14': 3, 'num_heads_14': 16, 'mlp_ratio_15': 4, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 16, 'mlp_ratio_17': 2, 'num_heads_17': 16, 'mlp_ratio_18': 3, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 8, 'mlp_ratio_20': 2, 'num_heads_20': 8, 'mlp_ratio_21': 2, 'num_heads_21': 16, 'mlp_ratio_22': 3, 'num_heads_22': 8, 'mlp_ratio_23': 4, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
INFO:syne_tune.tuner:tuning status (last metric is reported)
 trial_id     status  iter     type search_space surrogate_type objective device  num_layers  embed_dim  bias  mlp_ratio_0  num_heads_0  mlp_ratio_1  num_heads_1  mlp_ratio_2  num_heads_2  mlp_ratio_3  num_heads_3  mlp_ratio_4  num_heads_4  mlp_ratio_5  num_heads_5  mlp_ratio_6  num_heads_6  mlp_ratio_7  num_heads_7  mlp_ratio_8  num_heads_8  mlp_ratio_9  num_heads_9  mlp_ratio_10  num_heads_10  mlp_ratio_11  num_heads_11  mlp_ratio_12  num_heads_12  mlp_ratio_13  num_heads_13  mlp_ratio_14  num_heads_14  mlp_ratio_15  num_heads_15  mlp_ratio_16  num_heads_16  mlp_ratio_17  num_heads_17  mlp_ratio_18  num_heads_18  mlp_ratio_19  num_heads_19  mlp_ratio_20  num_heads_20  mlp_ratio_21  num_heads_21  mlp_ratio_22  num_heads_22  mlp_ratio_23  num_heads_23  epochs dataset_path  perplexity  hw_metric  worker-time
        0  Completed     1 quantile            m            mlp     flops   v100          24        256 False            3            8            3           12            3            8            4            8            3           12            3           16            3            8            2            8            2            8            4           16             2            16             2            16             3            12             4             8             4            12             2             8             2            12             4            12             3            12             4            12             3             8             4            12             3            12             4            12       1           ./    1.340196  -1.055749     0.727160
        1  Completed     1 quantile            m            mlp     flops   v100          24        512 False            4            8            3           12            2           12            3            8            4           12            2            8            3           16            4            8            3            8            2            8             4            16             4            12             2             8             3            12             2            12             3             8             3            16             4            12             4             8             2            16             2            12             4            12             4            16             4             8       1           ./   -0.120630  -0.471518     0.345232
        2  Completed     1 quantile            m            mlp     flops   v100          24        256  True            3           12            4           12            3           12            4            8            2           16            3           12            3           16            4           12            2           16            2            8             2             8             4             8             4             8             3            16             4             8             4             8             2            16             2             8             4             8             2            16             3            16             2            16             4            12             4             8       1           ./    1.413060  -1.037016     0.294330
        3 InProgress     0 quantile            m            mlp     flops   v100          23       1024  True            4           16            4           16            3            8            2           12            3           16            3            8            2            8            4            8            4            8            4           12             3            12             2            12             2             8             4            12             3            16             4             8             2            16             2            16             3            16             4             8             2             8             2            16             3             8             4             8       1           ./           -          -            -
1 trials running, 3 finished (3 until the end), 105.57s wallclock-time

DEBUG:syne_tune.optimizer.schedulers.fifo:trial_id 3 (perplexity = -1.071, hw_metric = 1.216): decision = CONTINUE
INFO:syne_tune.tuner:Trial trial_id 3 completed.
DEBUG:syne_tune.tuner:saving tuner in /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/tuner.dill
DEBUG:syne_tune.backend.local_backend:scheduling 4, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 24, 'embed_dim': 256, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 8, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 8, 'mlp_ratio_3': 4, 'num_heads_3': 12, 'mlp_ratio_4': 3, 'num_heads_4': 16, 'mlp_ratio_5': 4, 'num_heads_5': 16, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 3, 'num_heads_7': 12, 'mlp_ratio_8': 4, 'num_heads_8': 12, 'mlp_ratio_9': 3, 'num_heads_9': 8, 'mlp_ratio_10': 3, 'num_heads_10': 12, 'mlp_ratio_11': 2, 'num_heads_11': 16, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 4, 'num_heads_13': 12, 'mlp_ratio_14': 3, 'num_heads_14': 16, 'mlp_ratio_15': 3, 'num_heads_15': 12, 'mlp_ratio_16': 4, 'num_heads_16': 8, 'mlp_ratio_17': 3, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 8, 'mlp_ratio_19': 3, 'num_heads_19': 12, 'mlp_ratio_20': 2, 'num_heads_20': 16, 'mlp_ratio_21': 2, 'num_heads_21': 16, 'mlp_ratio_22': 4, 'num_heads_22': 12, 'mlp_ratio_23': 3, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/4
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 24 --embed_dim 256 --bias True --mlp_ratio_0 4 --num_heads_0 8 --mlp_ratio_1 3 --num_heads_1 8 --mlp_ratio_2 4 --num_heads_2 8 --mlp_ratio_3 4 --num_heads_3 12 --mlp_ratio_4 3 --num_heads_4 16 --mlp_ratio_5 4 --num_heads_5 16 --mlp_ratio_6 3 --num_heads_6 12 --mlp_ratio_7 3 --num_heads_7 12 --mlp_ratio_8 4 --num_heads_8 12 --mlp_ratio_9 3 --num_heads_9 8 --mlp_ratio_10 3 --num_heads_10 12 --mlp_ratio_11 2 --num_heads_11 16 --mlp_ratio_12 2 --num_heads_12 16 --mlp_ratio_13 4 --num_heads_13 12 --mlp_ratio_14 3 --num_heads_14 16 --mlp_ratio_15 3 --num_heads_15 12 --mlp_ratio_16 4 --num_heads_16 8 --mlp_ratio_17 3 --num_heads_17 8 --mlp_ratio_18 4 --num_heads_18 8 --mlp_ratio_19 3 --num_heads_19 12 --mlp_ratio_20 2 --num_heads_20 16 --mlp_ratio_21 2 --num_heads_21 16 --mlp_ratio_22 4 --num_heads_22 12 --mlp_ratio_23 3 --num_heads_23 8 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/4/checkpoints
INFO:syne_tune.tuner:(trial 4) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 24, 'embed_dim': 256, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 8, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 8, 'mlp_ratio_3': 4, 'num_heads_3': 12, 'mlp_ratio_4': 3, 'num_heads_4': 16, 'mlp_ratio_5': 4, 'num_heads_5': 16, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 3, 'num_heads_7': 12, 'mlp_ratio_8': 4, 'num_heads_8': 12, 'mlp_ratio_9': 3, 'num_heads_9': 8, 'mlp_ratio_10': 3, 'num_heads_10': 12, 'mlp_ratio_11': 2, 'num_heads_11': 16, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 4, 'num_heads_13': 12, 'mlp_ratio_14': 3, 'num_heads_14': 16, 'mlp_ratio_15': 3, 'num_heads_15': 12, 'mlp_ratio_16': 4, 'num_heads_16': 8, 'mlp_ratio_17': 3, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 8, 'mlp_ratio_19': 3, 'num_heads_19': 12, 'mlp_ratio_20': 2, 'num_heads_20': 16, 'mlp_ratio_21': 2, 'num_heads_21': 16, 'mlp_ratio_22': 4, 'num_heads_22': 12, 'mlp_ratio_23': 3, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.optimizer.schedulers.fifo:trial_id 4 (perplexity = 1.331, hw_metric = -1.040): decision = CONTINUE
INFO:syne_tune.tuner:Trial trial_id 4 completed.
DEBUG:syne_tune.tuner:saving tuner in /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/tuner.dill
DEBUG:syne_tune.backend.local_backend:scheduling 5, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 24, 'embed_dim': 1024, 'bias': False, 'mlp_ratio_0': 3, 'num_heads_0': 12, 'mlp_ratio_1': 4, 'num_heads_1': 8, 'mlp_ratio_2': 3, 'num_heads_2': 12, 'mlp_ratio_3': 2, 'num_heads_3': 16, 'mlp_ratio_4': 2, 'num_heads_4': 16, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 16, 'mlp_ratio_7': 2, 'num_heads_7': 8, 'mlp_ratio_8': 2, 'num_heads_8': 8, 'mlp_ratio_9': 4, 'num_heads_9': 8, 'mlp_ratio_10': 2, 'num_heads_10': 8, 'mlp_ratio_11': 4, 'num_heads_11': 16, 'mlp_ratio_12': 4, 'num_heads_12': 8, 'mlp_ratio_13': 2, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 16, 'mlp_ratio_16': 3, 'num_heads_16': 16, 'mlp_ratio_17': 3, 'num_heads_17': 12, 'mlp_ratio_18': 2, 'num_heads_18': 12, 'mlp_ratio_19': 2, 'num_heads_19': 12, 'mlp_ratio_20': 2, 'num_heads_20': 8, 'mlp_ratio_21': 3, 'num_heads_21': 8, 'mlp_ratio_22': 3, 'num_heads_22': 12, 'mlp_ratio_23': 2, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/5
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 24 --embed_dim 1024 --bias False --mlp_ratio_0 3 --num_heads_0 12 --mlp_ratio_1 4 --num_heads_1 8 --mlp_ratio_2 3 --num_heads_2 12 --mlp_ratio_3 2 --num_heads_3 16 --mlp_ratio_4 2 --num_heads_4 16 --mlp_ratio_5 4 --num_heads_5 12 --mlp_ratio_6 3 --num_heads_6 16 --mlp_ratio_7 2 --num_heads_7 8 --mlp_ratio_8 2 --num_heads_8 8 --mlp_ratio_9 4 --num_heads_9 8 --mlp_ratio_10 2 --num_heads_10 8 --mlp_ratio_11 4 --num_heads_11 16 --mlp_ratio_12 4 --num_heads_12 8 --mlp_ratio_13 2 --num_heads_13 8 --mlp_ratio_14 4 --num_heads_14 16 --mlp_ratio_15 2 --num_heads_15 16 --mlp_ratio_16 3 --num_heads_16 16 --mlp_ratio_17 3 --num_heads_17 12 --mlp_ratio_18 2 --num_heads_18 12 --mlp_ratio_19 2 --num_heads_19 12 --mlp_ratio_20 2 --num_heads_20 8 --mlp_ratio_21 3 --num_heads_21 8 --mlp_ratio_22 3 --num_heads_22 12 --mlp_ratio_23 2 --num_heads_23 8 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-48-726/5/checkpoints
INFO:syne_tune.tuner:(trial 5) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 24, 'embed_dim': 1024, 'bias': False, 'mlp_ratio_0': 3, 'num_heads_0': 12, 'mlp_ratio_1': 4, 'num_heads_1': 8, 'mlp_ratio_2': 3, 'num_heads_2': 12, 'mlp_ratio_3': 2, 'num_heads_3': 16, 'mlp_ratio_4': 2, 'num_heads_4': 16, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 16, 'mlp_ratio_7': 2, 'num_heads_7': 8, 'mlp_ratio_8': 2, 'num_heads_8': 8, 'mlp_ratio_9': 4, 'num_heads_9': 8, 'mlp_ratio_10': 2, 'num_heads_10': 8, 'mlp_ratio_11': 4, 'num_heads_11': 16, 'mlp_ratio_12': 4, 'num_heads_12': 8, 'mlp_ratio_13': 2, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 16, 'mlp_ratio_16': 3, 'num_heads_16': 16, 'mlp_ratio_17': 3, 'num_heads_17': 12, 'mlp_ratio_18': 2, 'num_heads_18': 12, 'mlp_ratio_19': 2, 'num_heads_19': 12, 'mlp_ratio_20': 2, 'num_heads_20': 8, 'mlp_ratio_21': 3, 'num_heads_21': 8, 'mlp_ratio_22': 3, 'num_heads_22': 12, 'mlp_ratio_23': 2, 'num_heads_23': 8, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
INFO:syne_tune.tuner:tuning status (last metric is reported)
 trial_id     status  iter     type search_space surrogate_type objective device  num_layers  embed_dim  bias  mlp_ratio_0  num_heads_0  mlp_ratio_1  num_heads_1  mlp_ratio_2  num_heads_2  mlp_ratio_3  num_heads_3  mlp_ratio_4  num_heads_4  mlp_ratio_5  num_heads_5  mlp_ratio_6  num_heads_6  mlp_ratio_7  num_heads_7  mlp_ratio_8  num_heads_8  mlp_ratio_9  num_heads_9  mlp_ratio_10  num_heads_10  mlp_ratio_11  num_heads_11  mlp_ratio_12  num_heads_12  mlp_ratio_13  num_heads_13  mlp_ratio_14  num_heads_14  mlp_ratio_15  num_heads_15  mlp_ratio_16  num_heads_16  mlp_ratio_17  num_heads_17  mlp_ratio_18  num_heads_18  mlp_ratio_19  num_heads_19  mlp_ratio_20  num_heads_20  mlp_ratio_21  num_heads_21  mlp_ratio_22  num_heads_22  mlp_ratio_23  num_heads_23  epochs dataset_path  perplexity  hw_metric  worker-time
        0  Completed     1 quantile            m            mlp     flops   v100          24        256 False            3            8            3           12            3            8            4            8            3           12            3           16            3            8            2            8            2            8            4           16             2            16             2            16             3            12             4             8             4            12             2             8             2            12             4            12             3            12             4            12             3             8             4            12             3            12             4            12       1           ./    1.340196  -1.055749     0.727160
        1  Completed     1 quantile            m            mlp     flops   v100          24        512 False            4            8            3           12            2           12            3            8            4           12            2            8            3           16            4            8            3            8            2            8             4            16             4            12             2             8             3            12             2            12             3             8             3            16             4            12             4             8             2            16             2            12             4            12             4            16             4             8       1           ./   -0.120630  -0.471518     0.345232
        2  Completed     1 quantile            m            mlp     flops   v100          24        256  True            3           12            4           12            3           12            4            8            2           16            3           12            3           16            4           12            2           16            2            8             2             8             4             8             4             8             3            16             4             8             4             8             2            16             2             8             4             8             2            16             3            16             2            16             4            12             4             8       1           ./    1.413060  -1.037016     0.294330
        3  Completed     1 quantile            m            mlp     flops   v100          23       1024  True            4           16            4           16            3            8            2           12            3           16            3            8            2            8            4            8            4            8            4           12             3            12             2            12             2             8             4            12             3            16             4             8             2            16             2            16             3            16             4             8             2             8             2            16             3             8             4             8       1           ./   -1.070739   1.216018     0.468365
        4  Completed     1 quantile            m            mlp     flops   v100          24        256  True            4            8            3            8            4            8            4           12            3           16            4           16            3           12            3           12            4           12            3            8             3            12             2            16             2            16             4            12             3            16             3            12             4             8             3             8             4             8             3            12             2            16             2            16             4            12             3             8       1           ./    1.331222  -1.040236     0.408909
        5 InProgress     0 quantile            m            mlp     flops   v100          24       1024 False            3           12            4            8            3           12            2           16            2           16            4           12            3           16            2            8            2            8            4            8             2             8             4            16             4             8             2             8             4            16             2            16             3            16             3            12             2            12             2            12             2             8             3             8             3            12             2             8       1           ./           -          -            -
1 trials running, 5 finished (5 until the end), 140.84s wallclock-time

DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
