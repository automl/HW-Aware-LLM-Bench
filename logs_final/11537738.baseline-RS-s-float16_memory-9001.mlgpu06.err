cpu-bind=MASK - mlgpu06, task  0  0 [2179]: mask 0x3000 set
INFO:syne_tune.optimizer.schedulers.scheduler_searcher:Master random_seed = 9001
INFO:syne_tune.optimizer.schedulers.scheduler_searcher:max_resource_level = 1, as inferred from config_space
INFO:syne_tune.tuner:results of trials will be saved on /home/sukthank/syne-tune/mogpt-2024-05-30-12-11-23-781
INFO:syne_tune.backend.local_backend:Detected 1 GPUs
DEBUG:syne_tune.backend.local_backend:scheduling 0, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 's', 'surrogate_type': 'mlp', 'objective': 'float16_memory', 'device': 'v100', 'num_layers': 10, 'embed_dim': 192, 'bias': True, 'mlp_ratio_0': 2, 'num_heads_0': 4, 'mlp_ratio_1': 2, 'num_heads_1': 4, 'mlp_ratio_2': 2, 'num_heads_2': 4, 'mlp_ratio_3': 2, 'num_heads_3': 4, 'mlp_ratio_4': 2, 'num_heads_4': 4, 'mlp_ratio_5': 2, 'num_heads_5': 4, 'mlp_ratio_6': 2, 'num_heads_6': 4, 'mlp_ratio_7': 2, 'num_heads_7': 4, 'mlp_ratio_8': 2, 'num_heads_8': 4, 'mlp_ratio_9': 2, 'num_heads_9': 4, 'mlp_ratio_10': 2, 'num_heads_10': 4, 'mlp_ratio_11': 2, 'num_heads_11': 4, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-11-23-781/0
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space s --surrogate_type mlp --objective float16_memory --device v100 --num_layers 10 --embed_dim 192 --bias True --mlp_ratio_0 2 --num_heads_0 4 --mlp_ratio_1 2 --num_heads_1 4 --mlp_ratio_2 2 --num_heads_2 4 --mlp_ratio_3 2 --num_heads_3 4 --mlp_ratio_4 2 --num_heads_4 4 --mlp_ratio_5 2 --num_heads_5 4 --mlp_ratio_6 2 --num_heads_6 4 --mlp_ratio_7 2 --num_heads_7 4 --mlp_ratio_8 2 --num_heads_8 4 --mlp_ratio_9 2 --num_heads_9 4 --mlp_ratio_10 2 --num_heads_10 4 --mlp_ratio_11 2 --num_heads_11 4 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-11-23-781/0/checkpoints
INFO:syne_tune.tuner:(trial 0) - scheduled config {'type': 'quantile', 'search_space': 's', 'surrogate_type': 'mlp', 'objective': 'float16_memory', 'device': 'v100', 'num_layers': 10, 'embed_dim': 192, 'bias': True, 'mlp_ratio_0': 2, 'num_heads_0': 4, 'mlp_ratio_1': 2, 'num_heads_1': 4, 'mlp_ratio_2': 2, 'num_heads_2': 4, 'mlp_ratio_3': 2, 'num_heads_3': 4, 'mlp_ratio_4': 2, 'num_heads_4': 4, 'mlp_ratio_5': 2, 'num_heads_5': 4, 'mlp_ratio_6': 2, 'num_heads_6': 4, 'mlp_ratio_7': 2, 'num_heads_7': 4, 'mlp_ratio_8': 2, 'num_heads_8': 4, 'mlp_ratio_9': 2, 'num_heads_9': 4, 'mlp_ratio_10': 2, 'num_heads_10': 4, 'mlp_ratio_11': 2, 'num_heads_11': 4, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
slurmstepd-mlgpu06: error: *** JOB 11537738 ON mlgpu06 CANCELLED AT 2024-05-30T14:11:46 ***
