cpu-bind=MASK - mlgpu10, task  0  0 [3337]: mask 0x300 set
INFO:syne_tune.optimizer.schedulers.scheduler_searcher:Master random_seed = 9001
INFO:syne_tune.optimizer.schedulers.scheduler_searcher:max_resource_level = 1, as inferred from config_space
INFO:syne_tune.tuner:results of trials will be saved on /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414
INFO:syne_tune.backend.local_backend:Detected 0 GPUs
WARNING:syne_tune.backend.local_backend:num_gpus_per_trial = 1 is too large, reducing to 0
DEBUG:syne_tune.backend.local_backend:scheduling 0, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 4, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 2, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/0
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 23 --embed_dim 512 --bias True --mlp_ratio_0 4 --num_heads_0 12 --mlp_ratio_1 3 --num_heads_1 8 --mlp_ratio_2 4 --num_heads_2 12 --mlp_ratio_3 4 --num_heads_3 8 --mlp_ratio_4 3 --num_heads_4 8 --mlp_ratio_5 4 --num_heads_5 12 --mlp_ratio_6 3 --num_heads_6 12 --mlp_ratio_7 4 --num_heads_7 12 --mlp_ratio_8 3 --num_heads_8 16 --mlp_ratio_9 2 --num_heads_9 8 --mlp_ratio_10 4 --num_heads_10 12 --mlp_ratio_11 4 --num_heads_11 12 --mlp_ratio_12 2 --num_heads_12 16 --mlp_ratio_13 3 --num_heads_13 8 --mlp_ratio_14 4 --num_heads_14 16 --mlp_ratio_15 2 --num_heads_15 8 --mlp_ratio_16 2 --num_heads_16 8 --mlp_ratio_17 4 --num_heads_17 8 --mlp_ratio_18 4 --num_heads_18 16 --mlp_ratio_19 4 --num_heads_19 16 --mlp_ratio_20 4 --num_heads_20 8 --mlp_ratio_21 4 --num_heads_21 16 --mlp_ratio_22 2 --num_heads_22 12 --mlp_ratio_23 4 --num_heads_23 12 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/0/checkpoints
INFO:syne_tune.tuner:(trial 0) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 4, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 2, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.optimizer.schedulers.fifo:trial_id 0 (perplexity = -0.168, hw_metric = -0.464): decision = CONTINUE
INFO:syne_tune.tuner:Trial trial_id 0 completed.
DEBUG:syne_tune.tuner:saving tuner in /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/tuner.dill
DEBUG:syne_tune.backend.local_backend:scheduling 1, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 4, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 3, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/1
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 23 --embed_dim 512 --bias True --mlp_ratio_0 4 --num_heads_0 12 --mlp_ratio_1 3 --num_heads_1 8 --mlp_ratio_2 4 --num_heads_2 12 --mlp_ratio_3 4 --num_heads_3 8 --mlp_ratio_4 3 --num_heads_4 8 --mlp_ratio_5 4 --num_heads_5 12 --mlp_ratio_6 3 --num_heads_6 12 --mlp_ratio_7 4 --num_heads_7 12 --mlp_ratio_8 3 --num_heads_8 16 --mlp_ratio_9 2 --num_heads_9 8 --mlp_ratio_10 4 --num_heads_10 12 --mlp_ratio_11 4 --num_heads_11 12 --mlp_ratio_12 2 --num_heads_12 16 --mlp_ratio_13 3 --num_heads_13 8 --mlp_ratio_14 4 --num_heads_14 16 --mlp_ratio_15 2 --num_heads_15 8 --mlp_ratio_16 2 --num_heads_16 8 --mlp_ratio_17 4 --num_heads_17 8 --mlp_ratio_18 4 --num_heads_18 16 --mlp_ratio_19 4 --num_heads_19 16 --mlp_ratio_20 4 --num_heads_20 8 --mlp_ratio_21 4 --num_heads_21 16 --mlp_ratio_22 3 --num_heads_22 12 --mlp_ratio_23 4 --num_heads_23 12 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/1/checkpoints
INFO:syne_tune.tuner:(trial 1) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 4, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 3, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
INFO:syne_tune.tuner:tuning status (last metric is reported)
 trial_id     status  iter     type search_space surrogate_type objective device  num_layers  embed_dim  bias  mlp_ratio_0  num_heads_0  mlp_ratio_1  num_heads_1  mlp_ratio_2  num_heads_2  mlp_ratio_3  num_heads_3  mlp_ratio_4  num_heads_4  mlp_ratio_5  num_heads_5  mlp_ratio_6  num_heads_6  mlp_ratio_7  num_heads_7  mlp_ratio_8  num_heads_8  mlp_ratio_9  num_heads_9  mlp_ratio_10  num_heads_10  mlp_ratio_11  num_heads_11  mlp_ratio_12  num_heads_12  mlp_ratio_13  num_heads_13  mlp_ratio_14  num_heads_14  mlp_ratio_15  num_heads_15  mlp_ratio_16  num_heads_16  mlp_ratio_17  num_heads_17  mlp_ratio_18  num_heads_18  mlp_ratio_19  num_heads_19  mlp_ratio_20  num_heads_20  mlp_ratio_21  num_heads_21  mlp_ratio_22  num_heads_22  mlp_ratio_23  num_heads_23  epochs dataset_path  perplexity  hw_metric  worker-time
        0  Completed     1 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             2            12             4            12       1           ./    -0.16804  -0.463578     0.893865
        1 InProgress     0 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             3            12             4            12       1           ./           -          -            -
1 trials running, 1 finished (1 until the end), 35.24s wallclock-time

DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.optimizer.schedulers.fifo:trial_id 1 (perplexity = -0.174, hw_metric = -0.457): decision = CONTINUE
DEBUG:syne_tune.tuner:saving tuner in /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/tuner.dill
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
INFO:syne_tune.tuner:Trial trial_id 1 completed.
DEBUG:syne_tune.backend.local_backend:scheduling 2, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 2, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 4, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 3, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/2
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 23 --embed_dim 512 --bias True --mlp_ratio_0 4 --num_heads_0 12 --mlp_ratio_1 3 --num_heads_1 8 --mlp_ratio_2 2 --num_heads_2 12 --mlp_ratio_3 4 --num_heads_3 8 --mlp_ratio_4 3 --num_heads_4 8 --mlp_ratio_5 4 --num_heads_5 12 --mlp_ratio_6 3 --num_heads_6 12 --mlp_ratio_7 4 --num_heads_7 12 --mlp_ratio_8 3 --num_heads_8 16 --mlp_ratio_9 2 --num_heads_9 8 --mlp_ratio_10 4 --num_heads_10 12 --mlp_ratio_11 4 --num_heads_11 12 --mlp_ratio_12 2 --num_heads_12 16 --mlp_ratio_13 3 --num_heads_13 8 --mlp_ratio_14 4 --num_heads_14 16 --mlp_ratio_15 2 --num_heads_15 8 --mlp_ratio_16 2 --num_heads_16 8 --mlp_ratio_17 4 --num_heads_17 8 --mlp_ratio_18 4 --num_heads_18 16 --mlp_ratio_19 4 --num_heads_19 16 --mlp_ratio_20 4 --num_heads_20 8 --mlp_ratio_21 4 --num_heads_21 16 --mlp_ratio_22 3 --num_heads_22 12 --mlp_ratio_23 4 --num_heads_23 12 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/2/checkpoints
INFO:syne_tune.tuner:(trial 2) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 2, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 4, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 3, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
INFO:syne_tune.tuner:tuning status (last metric is reported)
 trial_id     status  iter     type search_space surrogate_type objective device  num_layers  embed_dim  bias  mlp_ratio_0  num_heads_0  mlp_ratio_1  num_heads_1  mlp_ratio_2  num_heads_2  mlp_ratio_3  num_heads_3  mlp_ratio_4  num_heads_4  mlp_ratio_5  num_heads_5  mlp_ratio_6  num_heads_6  mlp_ratio_7  num_heads_7  mlp_ratio_8  num_heads_8  mlp_ratio_9  num_heads_9  mlp_ratio_10  num_heads_10  mlp_ratio_11  num_heads_11  mlp_ratio_12  num_heads_12  mlp_ratio_13  num_heads_13  mlp_ratio_14  num_heads_14  mlp_ratio_15  num_heads_15  mlp_ratio_16  num_heads_16  mlp_ratio_17  num_heads_17  mlp_ratio_18  num_heads_18  mlp_ratio_19  num_heads_19  mlp_ratio_20  num_heads_20  mlp_ratio_21  num_heads_21  mlp_ratio_22  num_heads_22  mlp_ratio_23  num_heads_23  epochs dataset_path  perplexity  hw_metric  worker-time
        0  Completed     1 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             2            12             4            12       1           ./   -0.168040  -0.463578     0.893865
        1  Completed     1 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             3            12             4            12       1           ./   -0.174017  -0.457274     0.410250
        2 InProgress     0 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            2           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             3            12             4            12       1           ./           -          -            -
1 trials running, 2 finished (2 until the end), 70.32s wallclock-time

DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.optimizer.schedulers.fifo:trial_id 2 (perplexity = -0.162, hw_metric = -0.470): decision = CONTINUE
INFO:syne_tune.tuner:Trial trial_id 2 completed.
DEBUG:syne_tune.tuner:saving tuner in /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/tuner.dill
DEBUG:syne_tune.backend.local_backend:scheduling 3, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 2, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 2, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/3
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 23 --embed_dim 512 --bias True --mlp_ratio_0 4 --num_heads_0 12 --mlp_ratio_1 3 --num_heads_1 8 --mlp_ratio_2 4 --num_heads_2 12 --mlp_ratio_3 4 --num_heads_3 8 --mlp_ratio_4 3 --num_heads_4 8 --mlp_ratio_5 4 --num_heads_5 12 --mlp_ratio_6 3 --num_heads_6 12 --mlp_ratio_7 4 --num_heads_7 12 --mlp_ratio_8 3 --num_heads_8 16 --mlp_ratio_9 2 --num_heads_9 8 --mlp_ratio_10 4 --num_heads_10 12 --mlp_ratio_11 4 --num_heads_11 12 --mlp_ratio_12 2 --num_heads_12 16 --mlp_ratio_13 3 --num_heads_13 8 --mlp_ratio_14 4 --num_heads_14 16 --mlp_ratio_15 2 --num_heads_15 8 --mlp_ratio_16 2 --num_heads_16 8 --mlp_ratio_17 2 --num_heads_17 8 --mlp_ratio_18 4 --num_heads_18 16 --mlp_ratio_19 4 --num_heads_19 16 --mlp_ratio_20 4 --num_heads_20 8 --mlp_ratio_21 4 --num_heads_21 16 --mlp_ratio_22 2 --num_heads_22 12 --mlp_ratio_23 4 --num_heads_23 12 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/3/checkpoints
INFO:syne_tune.tuner:(trial 3) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 2, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 2, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
INFO:syne_tune.tuner:tuning status (last metric is reported)
 trial_id     status  iter     type search_space surrogate_type objective device  num_layers  embed_dim  bias  mlp_ratio_0  num_heads_0  mlp_ratio_1  num_heads_1  mlp_ratio_2  num_heads_2  mlp_ratio_3  num_heads_3  mlp_ratio_4  num_heads_4  mlp_ratio_5  num_heads_5  mlp_ratio_6  num_heads_6  mlp_ratio_7  num_heads_7  mlp_ratio_8  num_heads_8  mlp_ratio_9  num_heads_9  mlp_ratio_10  num_heads_10  mlp_ratio_11  num_heads_11  mlp_ratio_12  num_heads_12  mlp_ratio_13  num_heads_13  mlp_ratio_14  num_heads_14  mlp_ratio_15  num_heads_15  mlp_ratio_16  num_heads_16  mlp_ratio_17  num_heads_17  mlp_ratio_18  num_heads_18  mlp_ratio_19  num_heads_19  mlp_ratio_20  num_heads_20  mlp_ratio_21  num_heads_21  mlp_ratio_22  num_heads_22  mlp_ratio_23  num_heads_23  epochs dataset_path  perplexity  hw_metric  worker-time
        0  Completed     1 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             2            12             4            12       1           ./   -0.168040  -0.463578     0.893865
        1  Completed     1 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             3            12             4            12       1           ./   -0.174017  -0.457274     0.410250
        2  Completed     1 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            2           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             3            12             4            12       1           ./   -0.162064  -0.469805     0.901843
        3 InProgress     0 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             2             8             4            16             4            16             4             8             4            16             2            12             4            12       1           ./           -          -            -
1 trials running, 3 finished (3 until the end), 105.41s wallclock-time

DEBUG:syne_tune.optimizer.schedulers.fifo:trial_id 3 (perplexity = -0.146, hw_metric = -0.476): decision = CONTINUE
INFO:syne_tune.tuner:Trial trial_id 3 completed.
DEBUG:syne_tune.tuner:saving tuner in /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/tuner.dill
DEBUG:syne_tune.backend.local_backend:scheduling 4, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 16, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 4, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 3, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/4
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 23 --embed_dim 512 --bias True --mlp_ratio_0 4 --num_heads_0 12 --mlp_ratio_1 3 --num_heads_1 8 --mlp_ratio_2 4 --num_heads_2 12 --mlp_ratio_3 4 --num_heads_3 8 --mlp_ratio_4 3 --num_heads_4 8 --mlp_ratio_5 4 --num_heads_5 12 --mlp_ratio_6 3 --num_heads_6 12 --mlp_ratio_7 4 --num_heads_7 12 --mlp_ratio_8 3 --num_heads_8 16 --mlp_ratio_9 2 --num_heads_9 16 --mlp_ratio_10 4 --num_heads_10 12 --mlp_ratio_11 4 --num_heads_11 12 --mlp_ratio_12 2 --num_heads_12 16 --mlp_ratio_13 3 --num_heads_13 8 --mlp_ratio_14 4 --num_heads_14 16 --mlp_ratio_15 2 --num_heads_15 8 --mlp_ratio_16 2 --num_heads_16 8 --mlp_ratio_17 4 --num_heads_17 8 --mlp_ratio_18 4 --num_heads_18 16 --mlp_ratio_19 4 --num_heads_19 16 --mlp_ratio_20 4 --num_heads_20 8 --mlp_ratio_21 4 --num_heads_21 16 --mlp_ratio_22 3 --num_heads_22 12 --mlp_ratio_23 4 --num_heads_23 12 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/4/checkpoints
INFO:syne_tune.tuner:(trial 4) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 4, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 16, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 4, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 3, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.optimizer.schedulers.fifo:trial_id 4 (perplexity = -0.181, hw_metric = -0.449): decision = CONTINUE
INFO:syne_tune.tuner:Trial trial_id 4 completed.
DEBUG:syne_tune.tuner:saving tuner in /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/tuner.dill
DEBUG:syne_tune.backend.local_backend:scheduling 5, /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py, {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 2, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 4, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 2, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}, logging into /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/5
INFO:syne_tune.backend.local_backend:running subprocess with command: /home/sukthank/anaconda3/envs/hwllm/bin/python /work/dlclarge2/sukthank-hw-llm-bench/arxiv/HW-Aware-LLM-Bench/baselines/gpt_objective_2d.py --type quantile --search_space m --surrogate_type mlp --objective flops --device v100 --num_layers 23 --embed_dim 512 --bias True --mlp_ratio_0 4 --num_heads_0 12 --mlp_ratio_1 3 --num_heads_1 8 --mlp_ratio_2 4 --num_heads_2 12 --mlp_ratio_3 4 --num_heads_3 8 --mlp_ratio_4 3 --num_heads_4 8 --mlp_ratio_5 4 --num_heads_5 12 --mlp_ratio_6 3 --num_heads_6 12 --mlp_ratio_7 2 --num_heads_7 12 --mlp_ratio_8 3 --num_heads_8 16 --mlp_ratio_9 2 --num_heads_9 8 --mlp_ratio_10 4 --num_heads_10 12 --mlp_ratio_11 4 --num_heads_11 12 --mlp_ratio_12 2 --num_heads_12 16 --mlp_ratio_13 3 --num_heads_13 8 --mlp_ratio_14 4 --num_heads_14 16 --mlp_ratio_15 2 --num_heads_15 8 --mlp_ratio_16 2 --num_heads_16 8 --mlp_ratio_17 4 --num_heads_17 8 --mlp_ratio_18 4 --num_heads_18 16 --mlp_ratio_19 4 --num_heads_19 16 --mlp_ratio_20 4 --num_heads_20 8 --mlp_ratio_21 4 --num_heads_21 16 --mlp_ratio_22 2 --num_heads_22 12 --mlp_ratio_23 4 --num_heads_23 12 --epochs 1 --dataset_path ./ --st_checkpoint_dir /home/sukthank/syne-tune/mogpt-2024-05-30-12-12-46-414/5/checkpoints
INFO:syne_tune.tuner:(trial 5) - scheduled config {'type': 'quantile', 'search_space': 'm', 'surrogate_type': 'mlp', 'objective': 'flops', 'device': 'v100', 'num_layers': 23, 'embed_dim': 512, 'bias': True, 'mlp_ratio_0': 4, 'num_heads_0': 12, 'mlp_ratio_1': 3, 'num_heads_1': 8, 'mlp_ratio_2': 4, 'num_heads_2': 12, 'mlp_ratio_3': 4, 'num_heads_3': 8, 'mlp_ratio_4': 3, 'num_heads_4': 8, 'mlp_ratio_5': 4, 'num_heads_5': 12, 'mlp_ratio_6': 3, 'num_heads_6': 12, 'mlp_ratio_7': 2, 'num_heads_7': 12, 'mlp_ratio_8': 3, 'num_heads_8': 16, 'mlp_ratio_9': 2, 'num_heads_9': 8, 'mlp_ratio_10': 4, 'num_heads_10': 12, 'mlp_ratio_11': 4, 'num_heads_11': 12, 'mlp_ratio_12': 2, 'num_heads_12': 16, 'mlp_ratio_13': 3, 'num_heads_13': 8, 'mlp_ratio_14': 4, 'num_heads_14': 16, 'mlp_ratio_15': 2, 'num_heads_15': 8, 'mlp_ratio_16': 2, 'num_heads_16': 8, 'mlp_ratio_17': 4, 'num_heads_17': 8, 'mlp_ratio_18': 4, 'num_heads_18': 16, 'mlp_ratio_19': 4, 'num_heads_19': 16, 'mlp_ratio_20': 4, 'num_heads_20': 8, 'mlp_ratio_21': 4, 'num_heads_21': 16, 'mlp_ratio_22': 2, 'num_heads_22': 12, 'mlp_ratio_23': 4, 'num_heads_23': 12, 'epochs': 1, 'dataset_path': './'}
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
INFO:syne_tune.tuner:tuning status (last metric is reported)
 trial_id     status  iter     type search_space surrogate_type objective device  num_layers  embed_dim  bias  mlp_ratio_0  num_heads_0  mlp_ratio_1  num_heads_1  mlp_ratio_2  num_heads_2  mlp_ratio_3  num_heads_3  mlp_ratio_4  num_heads_4  mlp_ratio_5  num_heads_5  mlp_ratio_6  num_heads_6  mlp_ratio_7  num_heads_7  mlp_ratio_8  num_heads_8  mlp_ratio_9  num_heads_9  mlp_ratio_10  num_heads_10  mlp_ratio_11  num_heads_11  mlp_ratio_12  num_heads_12  mlp_ratio_13  num_heads_13  mlp_ratio_14  num_heads_14  mlp_ratio_15  num_heads_15  mlp_ratio_16  num_heads_16  mlp_ratio_17  num_heads_17  mlp_ratio_18  num_heads_18  mlp_ratio_19  num_heads_19  mlp_ratio_20  num_heads_20  mlp_ratio_21  num_heads_21  mlp_ratio_22  num_heads_22  mlp_ratio_23  num_heads_23  epochs dataset_path  perplexity  hw_metric  worker-time
        0  Completed     1 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             2            12             4            12       1           ./   -0.168040  -0.463578     0.893865
        1  Completed     1 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             3            12             4            12       1           ./   -0.174017  -0.457274     0.410250
        2  Completed     1 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            2           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             3            12             4            12       1           ./   -0.162064  -0.469805     0.901843
        3  Completed     1 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            4           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             2             8             4            16             4            16             4             8             4            16             2            12             4            12       1           ./   -0.145712  -0.475798     0.366514
        4  Completed     1 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            4           12            3           16            2           16             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             3            12             4            12       1           ./   -0.180645  -0.449394     0.336989
        5 InProgress     0 quantile            m            mlp     flops   v100          23        512  True            4           12            3            8            4           12            4            8            3            8            4           12            3           12            2           12            3           16            2            8             4            12             4            12             2            16             3             8             4            16             2             8             2             8             4             8             4            16             4            16             4             8             4            16             2            12             4            12       1           ./           -          -            -
1 trials running, 5 finished (5 until the end), 140.60s wallclock-time

DEBUG:syne_tune.tuner:1 of 1 workers are busy, wait for 5.0 seconds
